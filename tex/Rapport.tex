\documentclass[12pt,a4paper]{article}

\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pdfpages}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{parskip}

\usepackage[top=2cm,bottom=2cm,left=18mm,right=18mm]{geometry}

\lstdefinestyle{darkula}{backgroundcolor=\color[HTML]{2B2B2B}, 
    basicstyle=\ttfamily\color[HTML]{A9B7C6},  
    breakatwhitespace=false,         
    breaklines=true,        
    columns=fullflexible,
    commentstyle=\color[HTML]{808080},
    frame=single, 
    framexleftmargin=6mm,  
    keepspaces=true,
	keywordstyle=\color[HTML]{CC7832},
    numbers=left,                    
    numbersep=4pt, 	
    numberstyle=\ttfamily\small\color[HTML]{6897BB},
    otherkeywords={self},
	tabsize=2,
	showspaces=false,                
    showstringspaces=false,
    showtabs=false,
    stringstyle=\color[HTML]{6A8759}
}

\lstdefinestyle{default}{basicstyle=\ttfamily,  
    commentstyle=\color[HTML]{808080},
    keywordstyle=\color[HTML]{000080},
    otherkeywords={self},
    numberstyle=\tiny\color[HTML]{6897BB},
    stringstyle=\color[HTML]{008000},
    breakatwhitespace=false,         
    breaklines=true,        
    columns=fullflexible,          
    keepspaces=true,  
    numbers=left,                    
    numbersep=5pt, 	
	tabsize=2,
	showspaces=false,                
    showstringspaces=false,
    showtabs=false
}

\lstset{
	language=Python, 
    literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
      {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
      {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
      {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
      {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
      {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
      {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
      {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
      {Ã}{{\~A}}1 {ã}{{\~a}}1 {Õ}{{\~O}}1 {õ}{{\~o}}1
      {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
      {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
      {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
      {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
      {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
}

\author{Lucas David \& Théo Legras}

\title{Rapport de projet de reconnaissance d'images}
\date{}

\begin{document}
\maketitle

\section{Implémentation et utilisation du classificateur à distance minimum (DMIN)}

On choisi d'implémenter ce classificateur sous forme d'une classe, ceci étant le plus courant et le plus pratique pour encapsuler les comportements et stocker les données nécessaires (extrait du fichier {\textbf{\ttfamily dmin.py}):
\begin{lstlisting}[style=darkula]
import numpy as np

class DMIN:
	def __init__(self):
		self.data = np.array([])
		self.label = np.array([])
		self.n_samples = 0

	def fit(self, data, label):
		self.data = data
		self.label = label
		self.n_samples = len(set(label))
		return self
		
	def predict(self, data):
		return [self.label[np.argmin(np.sum(np.subtract(self.data, data[iterator]) ** 2, axis=1))] for iterator in range(0, len(data))]

	def score(self, data, label):
		return np.count_nonzero(self.predict(data) == label) / len(data)
\end{lstlisting}

L'utilisation se résumera à l'instanciation de \lstinline[style=default]|DMIN| à l'appel de \lstinline[style=default]|DMIN.fit| et selon l'usage l'appel de \lstinline[style=default]|DMIN.predict| et \lstinline[style=default]|DMIN.score|.
En particulier, on peut donc déterminer le taux de réussite via la fonction membre \lstinline[style=default]|DMIN.score(<données à tester>, <labels correspondants>)|.

Dans le cas de nos données de développement, on obtient un score de 68,80\% pour une exécution de 96,45 secondes.
Il est toujours intéressant de noter que si on teste l'ensemble d'entraînement, on obtient le score parfait... On verra plus tard que ce n'est pas le cas de tous les algorithmes car cela peut être un indicateur d'\textit{overfitting} (du surapprentissage ou de la surinterprétation), c'est-à-dire correspond trop étroitement aux données.

\section{Utilisation de l'analyse en composantes principales (PCA) et application à DMIN}

L'utilisation de l'Implémentation de la PCA (\lstinline[style=default]|sklearn.decompostion.PCA|) est plutôt simple. 
On peut choisir via le paramêtre \lstinline[style=default]|n_components| le nombre de dimensions à garder, \linebreak[4] si $0 \leq$  \lstinline[style=default]|n_components| $< 1$, on indique la proportion des données à garder en variance (\%).

Nous nous choisissons de faire nos tests en modulant en variance plus qu'en nombre de dimensions car la notion de variance peut être mise en parallèle avec la perte de précision à postériori de la PCA.
De plus cela permet d'écarter les cas de réductions dans des nombres dimensions proches (e.g. passer de 760 dims. à 700 dims. ne signifie pas grand chose alors que de 100 dims. à 40 dims. à un impact visible). Effectivement, selon le modèle on n'obtiendra pas la même courbe ``Variance des données par rapport aux nombres de dimensions'' et ce n'est généralement pas linéaire.

Globalement, nous appliquons dans les grandes ligne la PCA et DMIN sur les données réduites comme suit:
\begin{lstlisting}[style=darkula]
import numpy as np
from sklearn.decompostion import PCA

X = np.load('data/trn_img.npy')
Y = np.load('data/trn_lbl.npy')
devX = np.load('data/dev_img.npy')
devY = np.load('data/dev_lbl.npy')

pca = PCA(n_components=0.5) # Ici on garde 50% de la variance des données.
reducedX = pca.fit_transform(X) # On colle au modèle et on transforme X.
print('Dimensions: {}'.format(reducedX)) # On peut afficher le nombre de dimension en valeur.
reducedDevX = pca.transform(reducedDevX) # On transforme devX.

dmin = DMIN() # On utilise DMIN.
dmin.fit(reducedX, Y)
print('Score: {}'.format(dmin.score(reducedDevX, devY)))

\end{lstlisting}

En terme de vitesse d'exécution initialiser la PCA et l'appliquer se fait en temps très raisonnable et permet de réduire drastiquement le temps d'exécution de DMIN. De plus, on remarquera que le fait d'appliquer la PCA améliore un peu le score lorsque l'on garde jusqu'à 50\% de la variance des données, on peut se douter que le fait de retirer certaine dimensions à diminuer en quelques sortes le bruit de l'image néfaste dans le cas de l'algorithme DMIN.


\begin{tabular}{ll}
    \sffamily\small
	\begin{tabular}{|c|c|c|c|c|}
        \hline
        \tiny n (\%) & \tiny n (dims) & \tiny Execution time PCA & \tiny Score DMIN & \tiny Execution time DMIN \\
        \hline
        0,05         & 1              & 0,855s                   & 22,60\%          & 0,149s     \\
        0,1          & 1              & 0,809s                   & 22,60\%          & 0,157s     \\
        0,15         & 1              & 0,776s                   & 22,60\%          & 0,149s     \\
        0,2          & 1              & 0,779s                   & 22,60\%          & 0,155s     \\
        0,25         & 1              & 0,775s                   & 22,60\%          & 0,158s     \\
        0,3          & 2              & 0,791s                   & 45,18\%          & 0,207s     \\
        0,35         & 2              & 0,806s                   & 45,18\%          & 0,212s     \\
        0,4          & 2              & 0,772s                   & 45,18\%          & 0,21s      \\
        0,45         & 2              & 0,781s                   & 45,18\%          & 0,209s     \\
        0,5          & 3              & 0,780s                   & 56,30\%          & 0,256s     \\
        0,55         & 4              & 0,800s                   & 65,44\%          & 0,314s     \\
        0,6          & 5              & 0,821s                   & 68,64\%          & 0,329s     \\
        0,65         & 6              & 0,844s                   & 71,42\%          & 0,379s     \\
        0,7          & 9              & 0,814s                   & 76,28\%          & 0,501s     \\
        0,75         & 14             & 0,790s                   & 78,12\%          & 0,687s     \\
        0,8          & 24             & 0,806s                   & 80,50\%          & 1,076s     \\
        0,85         & 42             & 0,804s                   & 81,84\%          & 1,837s     \\
        0,9          & 82             & 0,807s                   & 82,56\%          & 4,129s     \\
        0,95         & 182            & 0,821s                   & 82,36\%          & 11,542s    \\
        1            & 784            & --                       & 68,80\%          & 96,458s    \\
        \hline
    \end{tabular}

    \includegraphics[scale=0.5]{PCA+DMIN.pdf}
\end{tabular}




\end{multicols}

\end{document}